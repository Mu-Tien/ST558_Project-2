ST558 Project 2
================
Mu-Tien, Lee

-   [Require package](#require-package)
-   [Read in data](#read-in-data)
-   [Summarize the training data](#summarize-the-training-data)
-   [Training Model](#training-model)
    -   [Tree-based model](#tree-based-model)
    -   [Boosted tree model](#boosted-tree-model)
-   [Predicting using the best tree-base model](#predicting-using-the-best-tree-base-model)
-   [Predicting using the best boosted-tree model](#predicting-using-the-best-boosted-tree-model)

Require package
===============

``` r
#install.packages("")
library(knitr)
library(rmarkdown)
library(MuMIn)
library(tidyverse)
library(caret)
library(corrplot)
library(readxl)
library(caret)
library(ggiraphExtra)
library(knitr)
library(ggplot2)
library(ggpubr)
library(rpart.plot)
library(rpart)
library(DT)
```

Read in data
============

``` r
#read in hour data
HourData <- read.csv("hour.csv")
HourData<- HourData %>% select(-casual, -registered)
HourData$yr <- as.factor(HourData$yr)
HourData$holiday <- as.factor(HourData$holiday)
HourData$workingday <- as.factor(HourData$workingday)

#filter data by weekday
HourData <-HourData %>% filter(weekday==params$w)
#showing data
HourData <-HourData %>% select(-weekday, -workingday,-instant)
tbl_df(HourData)
```

    ## # A tibble: 2,502 x 12
    ##    dteday season yr     mnth    hr holiday weathersit  temp atemp   hum
    ##    <chr>   <int> <fct> <int> <int> <fct>        <int> <dbl> <dbl> <dbl>
    ##  1 2011-~      1 0         1     0 0                2  0.46 0.454  0.88
    ##  2 2011-~      1 0         1     1 0                2  0.44 0.439  0.94
    ##  3 2011-~      1 0         1     2 0                2  0.42 0.424  1   
    ##  4 2011-~      1 0         1     3 0                2  0.46 0.454  0.94
    ##  5 2011-~      1 0         1     4 0                2  0.46 0.454  0.94
    ##  6 2011-~      1 0         1     6 0                3  0.42 0.424  0.77
    ##  7 2011-~      1 0         1     7 0                2  0.4  0.409  0.76
    ##  8 2011-~      1 0         1     8 0                3  0.4  0.409  0.71
    ##  9 2011-~      1 0         1     9 0                2  0.38 0.394  0.76
    ## 10 2011-~      1 0         1    10 0                2  0.36 0.348  0.81
    ## # ... with 2,492 more rows, and 2 more variables: windspeed <dbl>, cnt <int>

``` r
#Separate dataset into train (70%) and test (30%) data set
set.seed(1997)
train <- sample(1:nrow(HourData), size = nrow(HourData)*0.7)
test <- dplyr::setdiff(1:nrow(HourData), train)
HourDataTrain <- HourData[train, ]
HourDataTest <- HourData[test, ]
```

Summarize the training data
===========================

``` r
# plot the histogram of rental count
hist <- ggplot(data=HourDataTrain, aes(x=cnt))+geom_histogram(binwidth = 20, aes(color=yr))
hist <-hist+labs(title="Histogram of the retal count", x="rental count")
hist <-hist+scale_fill_discrete(labels=c(2011,2012))
hist
```

![](0%20_files/figure-markdown_github/summarizing%20data-1.png)

``` r
#prin out summary table for tempature humidity and windspeed
sum <- HourDataTrain%>% select(c(temp, atemp, hum, windspeed))
kable(apply(sum, 2,summary), caption="Numeric Summary for weather measurement", format ="html")
```

<table>
<caption>
Numeric Summary for weather measurement
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
temp
</th>
<th style="text-align:right;">
atemp
</th>
<th style="text-align:right;">
hum
</th>
<th style="text-align:right;">
windspeed
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Min.
</td>
<td style="text-align:right;">
0.0200000
</td>
<td style="text-align:right;">
0.045500
</td>
<td style="text-align:right;">
0.1700000
</td>
<td style="text-align:right;">
0.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
1st Qu.
</td>
<td style="text-align:right;">
0.3400000
</td>
<td style="text-align:right;">
0.333300
</td>
<td style="text-align:right;">
0.4800000
</td>
<td style="text-align:right;">
0.1045000
</td>
</tr>
<tr>
<td style="text-align:left;">
Median
</td>
<td style="text-align:right;">
0.4600000
</td>
<td style="text-align:right;">
0.454500
</td>
<td style="text-align:right;">
0.6300000
</td>
<td style="text-align:right;">
0.1642000
</td>
</tr>
<tr>
<td style="text-align:left;">
Mean
</td>
<td style="text-align:right;">
0.4845231
</td>
<td style="text-align:right;">
0.466063
</td>
<td style="text-align:right;">
0.6272758
</td>
<td style="text-align:right;">
0.1895766
</td>
</tr>
<tr>
<td style="text-align:left;">
3rd Qu.
</td>
<td style="text-align:right;">
0.6400000
</td>
<td style="text-align:right;">
0.621200
</td>
<td style="text-align:right;">
0.7800000
</td>
<td style="text-align:right;">
0.2537000
</td>
</tr>
<tr>
<td style="text-align:left;">
Max.
</td>
<td style="text-align:right;">
0.9600000
</td>
<td style="text-align:right;">
0.909100
</td>
<td style="text-align:right;">
1.0000000
</td>
<td style="text-align:right;">
0.7164000
</td>
</tr>
</tbody>
</table>
``` r
#plot the boxplot of tempature humidity and windspeed (not genralized amount)
#plot base
boxplot <- ggplot(data = HourDataTrain, aes(x=season))
#adding 4 variables
tem <-boxplot+geom_boxplot(aes(y=temp*41, group=season))+labs(y="Tempature (c)", title = "boxplot for weather measurement")
fetem <-boxplot+geom_boxplot(aes(y=atemp*50, group=season))+labs(y="Feeling Tempature (c)")
hum <-boxplot+geom_boxplot(aes(y=hum*100, group=season))+labs(y="Humidity")
wind <-boxplot+geom_boxplot(aes(y=windspeed*67, group=season))+labs(y="Wind Speed")
#combine 4 plots into 1
ggarrange(tem, fetem, hum , wind, ncol = 2, nrow = 2)
```

![](0%20_files/figure-markdown_github/summarizing%20data-2.png)

``` r
# plot the count distribution among time and weather
# by time
barplot1<-ggplot(data = HourDataTrain, aes(x=hr))+geom_col(aes(y=cnt, fill=yr))+facet_wrap(~mnth)
barplot1 <- barplot1+labs(x="time", y="Rental Count", title="Retal count distribution by month" )
barplot1+scale_fill_discrete(name="year", labels=c(2011,2012))
```

![](0%20_files/figure-markdown_github/summarizing%20data-3.png)

``` r
# by weather
barplot2 <-ggplot(data = HourDataTrain, aes(x=weathersit))+geom_col(aes(y=cnt, fill=yr))+facet_wrap(~mnth)
barplot2 <- barplot2+labs(x="Weather situation, 1: clear day, 2: misty day, 3:rain or snow", y="Rental Count", title="Retal count distribution by month" )
barplot2+scale_fill_discrete(name="year", labels=c(2011,2012))
```

![](0%20_files/figure-markdown_github/summarizing%20data-4.png)

Training Model
==============

Here I use two different method, First one useing a tree-based models using leave one out cross validation. Second, I use the boosted tree model with cross validation. Both two training are done using the `train` function from `caret` package. The data was cantered and scaled before training.Since our response variables is continuous response, I choose to use Regression tree.

Tree-based model
----------------

``` r
# set up training control, using leave one out cross validation.
set.seed(615)
trctrl <- trainControl(method = "LOOCV", number = 1)

# getModelInfo("rpart")
# training using regression tree models with cp in [0.001, 0.002]
# since the cp seems have to be really small when I used the default cp to train

model1 <- cnt~season+yr+mnth+hr+holiday+weathersit+temp+atemp+hum+windspeed

RegTree_fit1 <- train(model1, data = HourDataTrain, method = "rpart",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneGrid=expand.grid(cp=seq(0.0001,0.0015,0.00005))
)

# show the training result
RegTree_fit1
```

    ## CART 
    ## 
    ## 1751 samples
    ##   10 predictor
    ## 
    ## Pre-processing: centered (10), scaled (10) 
    ## Resampling: Leave-One-Out Cross-Validation 
    ## Summary of sample sizes: 1750, 1750, 1750, 1750, 1750, 1750, ... 
    ## Resampling results across tuning parameters:
    ## 
    ##   cp       RMSE      Rsquared   MAE     
    ##   0.00010  53.79026  0.8964324  35.17311
    ##   0.00015  54.19620  0.8949124  35.87487
    ##   0.00020  54.65095  0.8931293  36.59719
    ##   0.00025  54.89081  0.8922189  36.92180
    ##   0.00030  55.56135  0.8895528  37.73094
    ##   0.00035  55.36225  0.8903180  37.44915
    ##   0.00040  55.62551  0.8892783  37.60950
    ##   0.00045  55.99023  0.8877537  38.83082
    ##   0.00050  56.23099  0.8867383  39.14940
    ##   0.00055  56.48049  0.8856355  39.65133
    ##   0.00060  56.38848  0.8859248  39.65037
    ##   0.00065  56.77374  0.8843146  40.12413
    ##   0.00070  56.41535  0.8857611  39.61205
    ##   0.00075  56.56790  0.8851069  40.13481
    ##   0.00080  56.47824  0.8853935  40.03673
    ##   0.00085  56.65729  0.8846508  40.12012
    ##   0.00090  56.58211  0.8849598  40.06127
    ##   0.00095  56.75547  0.8843037  40.14574
    ##   0.00100  57.29991  0.8820698  40.45070
    ##   0.00105  57.38366  0.8816927  40.51485
    ##   0.00110  57.74281  0.8802092  40.75558
    ##   0.00115  58.24249  0.8781215  41.14345
    ##   0.00120  58.69201  0.8762721  41.71876
    ##   0.00125  58.40211  0.8774654  41.22124
    ##   0.00130  58.28893  0.8780097  40.95876
    ##   0.00135  58.74831  0.8761758  41.32102
    ##   0.00140  59.27939  0.8738639  42.09073
    ##   0.00145  59.97982  0.8707490  42.69937
    ##   0.00150  60.28472  0.8693244  42.97311
    ## 
    ## RMSE was used to select the optimal model using the smallest value.
    ## The final value used for the model was cp = 1e-04.

``` r
# plot the RMSE of selected cp
plot(RegTree_fit1)
```

![](0%20_files/figure-markdown_github/tree%20based%20model-1.png)

``` r
# plot my final tree model
rpart.plot(RegTree_fit1$finalModel)
```

![](0%20_files/figure-markdown_github/tree%20based%20model-2.png)

Boosted tree model
------------------

``` r
# set up training control, using cross validation with 10 folder
set.seed(615)
trctrl <- trainControl(method = "cv", number = 10)

# training using boosted tree models with boosting interation in [200,400] and try max tree depth 5~9
model2 <- cnt~season+yr+mnth+hr+holiday+weathersit+temp+atemp+hum+windspeed
RegTree_fit2 <- train(model2, data = HourDataTrain, method = "gbm",
                trControl=trctrl,
                preProcess = c("center", "scale"),
                tuneGrid=expand.grid(n.trees=seq(800,1250,20),
                                     interaction.depth=6:10,
                                     shrinkage=0.1, n.minobsinnode=10)
                 )
```

``` r
# show the training result
RegTree_fit2$bestTune
```

    ##    n.trees interaction.depth shrinkage n.minobsinnode
    ## 25     820                 7       0.1             10

``` r
# plot the RMSE of selected parameters
plot(RegTree_fit2)
```

![](0%20_files/figure-markdown_github/boosted%20result-1.png)

Predicting using the best tree-base model
=========================================

``` r
# predict use predict function
tree_pred <- predict(RegTree_fit1, newdata = HourDataTest)

#Calculate the Root MSE
RMSE_tree<- sqrt(mean((tree_pred-HourDataTest$cnt)^2))
label <- paste0("RMSE =", RMSE_tree)

# plot the prediction
count <- data.frame(true_count=HourDataTest$cnt,prediction=tree_pred )
predPlot <- ggplot(data=count, aes(x=true_count,y=prediction))
predPlot <- predPlot+labs(title="Prediction V.s. True Count using tree-base model")+geom_point()
predPlot <- predPlot+geom_smooth(color="orange")+geom_abline(aes(intercept=0,slope=1), color="blue")
predPlot <- predPlot+geom_text(x=200, y=800,label=label, color="brown")
predPlot
```

![](0%20_files/figure-markdown_github/predicting%20tree%20model-1.png)

Predicting using the best boosted-tree model
============================================

``` r
# predict use predict function
boosted_pred <- predict(RegTree_fit2, newdata = HourDataTest)

#Calculate the Root MSE
RMSE_boosted <- sqrt(mean((boosted_pred-HourDataTest$cnt)^2))
lab <- paste0("RMSE =", RMSE_boosted)
# plot the prediction
count2 <- data.frame(True_count=HourDataTest$cnt,prediction=boosted_pred )
pred_plot <- ggplot(data=count2, aes(x=True_count,y=prediction))
pred_plot <- pred_plot+labs(title="Prediction V.s. True Count using boosted model")+geom_point()
pred_plot <- pred_plot+geom_smooth(color="orange")+geom_abline(aes(intercept=0,slope=1), color="blue")
pred_plot <- pred_plot+geom_text(x=200, y=800,label=lab, color=" brown")
pred_plot
```

![](0%20_files/figure-markdown_github/predicting%20boosted%20model-1.png)
